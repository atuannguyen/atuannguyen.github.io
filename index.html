<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>A. Tuan Nguyen</title>
    <meta name="author" content="A. Tuan  Nguyen" />
    <meta name="description" content="My personal website.
" />
    <meta name="keywords" content="tuan, A. Tuan Nguyen, tuan nguyen, oxford, meta, janestreet" />


    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.ico"/>
    

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-navsticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://atuannguyen.com/">A. Tuan Nguyen</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/collaborators/">Collaborators</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <br>
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           A. Tuan Nguyen
          </h1>
          <p class="desc"><a href="https://www.janestreet.com" target="_blank" rel="noopener noreferrer">Researcher, Jane Street</a> <br>New York, NY, United States</p>
        </header>

        <article>
          <div class="profile float-right">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/ava-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/ava-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/ava-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/ava.jpg">
  </picture>

</figure>

            <div class="address">
              <p>"The past is just practice"</p>

            </div>
          </div>

          <div class="clearfix">
            <p>I am a Quant Researcher at Jane Street, working on quant finance and related machine learning problems. Prior to that, I was a Research Scientist at Meta, working on large multi-modal language model for the search problems.</p>

<p>I obtained a PhD (DPhil) in Machine Learning from the University of Oxford. During my time at Oxford, I was fortunate to have worked with <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank" rel="noopener noreferrer">Prof. Philip Torr</a>, <a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/" target="_blank" rel="noopener noreferrer">Prof. Yarin Gal</a>, and <a href="https://www.robots.ox.ac.uk/~gunes/" target="_blank" rel="noopener noreferrer">Dr. Gunes Baydin</a>. My PhD thesis focused on addressing the distribution shift problem in machine learning. Before my doctoral studies, I pursued a Master’s degree at Korea Advanced Institute of Science and Technology. During this period, I worked as a research assistant at KAIST’s <a href="https://www.mlai-kaist.com/" target="_blank" rel="noopener noreferrer">MLAI Group</a>, supervised by Prof. Sung Ju Hwang.</p>

<p>My (might-be-outdated) resume is available <a href="assets/pdf/resume.pdf">here</a>. You can reach out to me via email: a.tuan.nguyen at outlook.com</p>

          </div>

          <!-- News -->          
          <div class="news">
            <h2>News</h2>
            <div class="table-responsive">
              <table class="table table-sm table-borderless"> 
                <tr>
                  <th scope="row">Mar 24, 2025</th>
                  <td>
                    I joined Jane Street as a Quant Researcher.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Aug 12, 2024</th>
                  <td>
                    A paper (uCAP) has been accepted to ECCV as oral.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 8, 2024</th>
                  <td>
                    I join Meta (New York) as a Research Scientist.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 7, 2023</th>
                  <td>
                    Arrived in Menlo Park for an internship at Meta. Let’s connect!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 27, 2023</th>
                  <td>
                    A paper accepted to CVPR 2023!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Sep 15, 2022</th>
                  <td>
                    A paper gets accepted to NeurIPS 2022! Hope to see you in New Orleans.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 15, 2022</th>
                  <td>
                    A paper gets accepted to ICML 2022!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 21, 2022</th>
                  <td>
                    Two papers get accepted to ICLR 2022!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Dec 15, 2021</th>
                  <td>
                    Get an internship offer at Meta (Facebook). Going to San Francisco for a four-month internship!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Sep 28, 2021</th>
                  <td>
                    A paper gets accepted to NeurIPS 2021!
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Selected papers -->
          <div class="publications">
            <h2>Selected Publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ECCV</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2024ucap" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">uCAP: An Unsupervised Prompting Method for Vision-Language Models</div>
          <!-- Author -->
          <div class="author">
                  <em>A. Tuan Nguyen</em>, Kai Sheng Tai, Sirius Chen, Satya Narayan Shukla, Hanchao Yu, <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank" rel="noopener noreferrer">Philip Torr</a>, Taipeng Tian, and <a href="https://sites.google.com/site/sernam" target="_blank" rel="noopener noreferrer">Ser-Nam Lim</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>European Conference on Computer Vision (Oral)</em>, 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://eccv.ecva.net/virtual/2024/poster/2005" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/nguyen2024ucap.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper addresses a significant limitation that prevents Contrastive Language-Image Pretrained Models (CLIP) from achieving optimal performance on downstream image classification tasks. The key problem with CLIP-style zero-shot classification is that it requires domain-specific context in the form of prompts to better align the class descriptions to the downstream data distribution. In particular, prompts for vision-language models are domain-level texts (e.g., “a centered satellite image of ...”) which, together with the class names, are fed into the text encoder to provide more context for the downstream dataset. These prompts are typically manually tuned, which is time consuming and often sub-optimal. To overcome this bottleneck, this paper proposes uCAP, a method to automatically learn domain-specific prompts/contexts using only unlabeled in-domain images. We achieve this by modeling the generation of images given the class names and a domain-specific prompt with an unsupervised likelihood distribution, and then performing inference of the prompts. We validate the proposed method across various models and datasets, showing that uCAP consistently outperforms manually tuned prompts and related baselines on the evaluated datasets: ImageNet, CIFAR-10, CIFAR-100, OxfordPets (up to 2%), SUN397 (up to 5%), and Caltech101 (up to 3%).</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2024ucap</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ECCV}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://eccv.ecva.net/virtual/2024/poster/2005}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{nguyen2024ucap.pdf}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{uCAP: An Unsupervised Prompting Method for Vision-Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Tai, Kai Sheng and Chen, Sirius and Shukla, Satya Narayan and Yu, Hanchao and Torr, Philip and Tian, Taipeng and Lim, Ser-Nam}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision (Oral)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CVPR</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2023tipi" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">TIPI: Test Time Adaptation with Transformation Invariance</div>
          <!-- Author -->
          <div class="author">
                  <em>A. Tuan Nguyen</em>, <a href="https://thanhnguyentang.github.io/" target="_blank" rel="noopener noreferrer">Thanh Nguyen-Tang</a>, <a href="https://sites.google.com/site/sernam" target="_blank" rel="noopener noreferrer">Ser-Nam Lim</a>, and <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank" rel="noopener noreferrer">Philip Torr</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Nguyen_TIPI_Test_Time_Adaptation_With_Transformation_Invariance_CVPR_2023_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/CVPR_nguyen2023tipi.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>When deploying a machine learning model to a new environment, we often encounter the distribution shift problem – meaning the target data distribution is different from the model’s training distribution. In this paper, we assume that labels are not provided for this new domain, and that we do not store the source data (e.g., for privacy reasons). It has been shown that even small shifts in the data distribution can affect the model’s performance severely. Test Time Adaptation offers a means to combat this problem, as it allows the model to adapt during test time to the new data distribution, using only unlabeled test data batches. To achieve this, the predominant approach is to optimize a surrogate loss on the test-time unlabeled target data. In particular, minimizing the prediction’s entropy on target samples \citewang2020tent has received much interest as it is task-agnostic and does not require altering the model’s training phase (e.g., does not require adding a self-supervised task during training on the source domain). However, as the target data’s batch size is often small in real-world scenarios (e.g., autonomous driving models process each few frames in real-time), we argue that this surrogate loss is not optimal since it often collapses with small batch sizes. To tackle this problem, in this paper, we propose to use an invariance regularizer as the surrogate loss during test-time adaptation, motivated by our theoretical results regarding the model’s performance under input transformations. The resulting method (TIPI – Test tIme adaPtation with transformation Invariance) is validated with extensive experiments in various benchmarks (Cifar10-C, Cifar100-C, ImageNet-C, DIGITS, and VisDA17). Remarkably, TIPI is robust against small batch sizes (as small as 2 in our experiments), and consistently outperforms TENT \citewang2020tent in all settings.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2023tipi</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content/CVPR2023/html/Nguyen_TIPI_Test_Time_Adaptation_With_Transformation_Invariance_CVPR_2023_paper.html}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{CVPR_nguyen2023tipi.pdf}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TIPI: Test Time Adaptation with Transformation Invariance}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Nguyen-Tang, Thanh and Lim, Ser-Nam and Torr, Philip}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2022fedsr" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">FedSR: A Simple and Effective Domain Generalization Method for Federated Learning</div>
          <!-- Author -->
          <div class="author">
                  <em>A. Tuan Nguyen</em>, <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank" rel="noopener noreferrer">Philip Torr</a>, and <a href="https://sites.google.com/site/sernam" target="_blank" rel="noopener noreferrer">Ser-Nam Lim</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em>, 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openreview.net/forum?id=mrt90D00aQX" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/NeurIPS_nguyen2022fedsr.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Federated Learning (FL) refers to the decentralized and privacy-preserving machine learning framework in which multiple clients collaborate (with the help of a central server) to train a global model without sharing their data. However, most existing FL methods only focus on maximizing the model’s performance on the source clients’ data (e.g., mobile users) without considering its generalization ability to unknown target data (e.g., a new user). In this paper, we incorporate the problem of Domain Generalization (DG) into Federated Learning to tackle the aforementioned issue. However, virtually all existing DG methods require a centralized setting where data is shared across the domains, which violates the principles of decentralized FL and hence not applicable. To this end, we propose a simple yet novel representation learning framework, namely FedSR, which enables domain generalization while still respecting the decentralized and privacy-preserving natures of this FL setting. Motivated by classical machine learning algorithms, we aim to learn a simple representation of the data for better generalization. In particular, we enforce an L2-norm regularizer on the representation and a conditional mutual information (between the representation and the data given the label) regularizer to encourage the model to only learn essential information (while ignoring spurious correlations such as the background). Furthermore, we provide theoretical connections between the above two objectives and representation alignment in domain generalization. Extensive experimental results suggest that our method significantly outperforms relevant baselines in this particular problem.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2022fedsr</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{NeurIPS_nguyen2022fedsr.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=mrt90D00aQX}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FedSR: A Simple and Effective Domain Generalization Method for Federated Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Torr, Philip and Lim, Ser-Nam}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2022kl" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">KL Guided Domain Adaptation</div>
          <!-- Author -->
          <div class="author">
                  <em>A. Tuan Nguyen</em>, Toan Tran, <a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/" target="_blank" rel="noopener noreferrer">Yarin Gal</a>, <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank" rel="noopener noreferrer">Philip H. S. Torr</a>, and <a href="https://gbaydin.github.io/" target="_blank" rel="noopener noreferrer">Atılım Güneş Baydin</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>International Conference on Learning Representations</em>, 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openreview.net/forum?id=0JzqUlIVVDd" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/ICLR_nguyen2022kl.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Domain adaptation is an important problem and often needed for real-world ap-
plications. In this problem, instead of i.i.d. datapoints, we assume that the source
(training) data and the target (testing) data have different distributions. With that
setting, the empirical risk minimization training procedure often does not perform
well, since it does not account for the change in the distribution. A common
approach in the domain adaptation literature is to learn a representation of the input
that has the same distributions over the source and the target domain. However,
these approaches often require additional networks and/or optimizing an adversarial
(minimax) objective, which can be very expensive or unstable in practice. To tackle
this problem, we first derive a generalization bound for the target loss based on
the training loss and the reverse Kullback–Leibler (KL) divergence between the
source and the target representation distributions. Based on this bound, we derive
an algorithm that minimizes the KL term to obtain a better generalization to the
target domain. We show that with a probabilistic representation network, the KL
term can be estimated efficiently via minibatch samples without any additional
network or a minimax objective. This leads to a theoretically sound alignment
method which is also very efficient and stable in practice. Experimental results also
suggest that our method outperforms other representation-alignment approaches.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2022kl</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICLR}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{ICLR_nguyen2022kl.pdf}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=0JzqUlIVVDd}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{KL Guided Domain Adaptation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Tran, Toan and Gal, Yarin and Torr, Philip H. S. and Baydin, At{\i}l{\i}m G{\"u}ne{\c{s}}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2021domain" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Domain Invariant Representation Learning with Domain Density Transformations</div>
          <!-- Author -->
          <div class="author">
                  <em>A. Tuan Nguyen</em>, Toan Tran, <a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/" target="_blank" rel="noopener noreferrer">Yarin Gal</a>, and <a href="https://gbaydin.github.io/" target="_blank" rel="noopener noreferrer">Atılım Güneş Baydin</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em>, 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://papers.nips.cc/paper/2021/hash/2a2717956118b4d223ceca17ce3865e2-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/NeurIPS_nguyen2021domain.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Domain generalization refers to the problem where we aim to train a model on
data from a set of source domains so that the model can generalize to unseen target
domains. Naively training a model on the aggregate set of data (pooled from all
source domains) has been shown to perform suboptimally, since the information
learned by that model might be domain-specific and generalize imperfectly to target
domains. To tackle this problem, a predominant domain generalization approach
is to learn some domain-invariant information for the prediction task, aiming at
a good generalization across domains. In this paper, we propose a theoretically
grounded method to learn a domain-invariant representation by enforcing the
representation network to be invariant under all transformation functions among
domains. We next introduce the use of generative adversarial networks to learn such
domain transformations in a possible implementation of our method in practice.
We demonstrate the effectiveness of our method on several widely used datasets for
the domain generalization problem, on all of which we achieve competitive results
with state-of-the-art models.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2021domain</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{NeurIPS_nguyen2021domain.pdf}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://papers.nips.cc/paper/2021/hash/2a2717956118b4d223ceca17ce3865e2-Abstract.html}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Domain Invariant Representation Learning with Domain Density Transformations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Tran, Toan and Gal, Yarin and Baydin, At{\i}l{\i}m G{\"u}ne{\c{s}}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div>

        <!-- Entry bib key -->
        <div id="nguyen2021clinical" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning</div>
          <!-- Author -->
          <div class="author">
                  <em>A. Tuan Nguyen</em>, Hyewon Jeong, Eunho Yang, and Sung Ju Hwang
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17097" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/AAAI_nguyen2021clinical.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Although recent multi-task learning methods have shown to be effective in improving the generalization of deep neural networks, they should be used with caution for safety-critical applications, such as clinical risk prediction. This is because even if they achieve improved task-average performance, they may still yield degraded performance on individual tasks, which may be critical (e.g., prediction of mortality risk). Existing asymmetric multi-task learning methods tackle this negative transfer problem by performing knowledge transfer from tasks with low loss to tasks with high loss. However, using loss as a measure of reliability is risky since low loss could result from overfitting. In the case of time-series prediction tasks, knowledge learned for one task (e.g., predicting the sepsis onset) at a specific timestep may be useful for learning another task (e.g., prediction of mortality) at a later timestep, but lack of loss at each timestep makes it difficult to measure the reliability at each timestep. To capture such dynamically changing asymmetric relationships between tasks in time-series data, we propose a novel temporal asymmetric multi-task learning model that performs knowledge transfer from certain tasks/timesteps to relevant uncertain tasks, based on the feature-level uncertainty. We validate our model on multiple clinical risk prediction tasks against various deep learning models for time-series prediction, which our model significantly outperforms without any sign of negative transfer. Further qualitative analysis of learned knowledge graphs by clinicians shows that they are helpful in analyzing the predictions of the model.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2021clinical</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{AAAI}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{AAAI_nguyen2021clinical.pdf}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/17097}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/17097}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, A. Tuan and Jeong, Hyewon and Yang, Eunho and Hwang, Sung Ju}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9081-9091}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%61.%74%75%61%6E.%6E%67%75%79%65%6E@%6F%75%74%6C%6F%6F%6B.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=V-guxukAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/atuannguyen" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/atngn" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/a_t_ngn" title="X" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            
            </div>

            <div class="contact-note">
              The best way to reach me is via email.

            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2025 A. Tuan  Nguyen.  Last updated: October 18, 2025. <br>
        Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.
</div>
    </footer>
  </body>

  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  <!-- Mansory & imagesLoaded -->
  <script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  <script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
  
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  
</html>

